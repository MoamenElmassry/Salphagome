{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "from Bio import Entrez\n",
    "import time\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns; sns.set()\n",
    "import copy\n",
    "import numpy as np\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the locations below to the location of your two results folders.\n",
    "\n",
    "files_disease = glob.glob('ptyphi_results/*species.txt')\n",
    "files_control = glob.glob('typhi_results/*species.txt')\n",
    "\n",
    "location_of_fasta = 'databases/just_viruses/just_viruses.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of sequences in the reference FASTA\n",
    "fasta_ids = []\n",
    "\n",
    "with open(location_of_fasta, \"r\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\") :\n",
    "        fasta_ids.append(record.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get read hit counts from disease folder\n",
    "\n",
    "master_list = []\n",
    "\n",
    "for file in files_disease:\n",
    "    \n",
    "    list_of_seqs = copy.deepcopy(fasta_ids)\n",
    "    \n",
    "    name = str(file)\n",
    "    \n",
    "    with open(file, \"r\") as ifile:\n",
    "        \n",
    "        for line in ifile:\n",
    "            \n",
    "            data = line.strip().split(' ')\n",
    "            data = data+[name, 'ptyphi']\n",
    "            \n",
    "            list_of_seqs.remove(data[1])\n",
    "            \n",
    "            \n",
    "            master_list.append(data)\n",
    "            \n",
    "    for seq in list_of_seqs:\n",
    "        \n",
    "        data = [0, seq, name, 'ptyphi']\n",
    "        \n",
    "        master_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get read hit counts from control folder\n",
    "\n",
    "for file in files_control:\n",
    "    \n",
    "    name = str(file)\n",
    "    \n",
    "    list_of_seqs = copy.deepcopy(fasta_ids)\n",
    "    \n",
    "    with open(file, \"r\") as ifile:\n",
    "        \n",
    "        for line in ifile:\n",
    "            \n",
    "            data = line.strip().split(' ')\n",
    "            data = data+[name, 'typhi']\n",
    "            master_list.append(data)\n",
    "            \n",
    "            \n",
    "    for seq in list_of_seqs:\n",
    "        \n",
    "        data = [0, seq, name, 'typhi']\n",
    "        \n",
    "        master_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['count', 'seq', 'file', 'type'], data= master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_srr_accession(df):\n",
    "    \"\"\"\n",
    "    Extract the SRR number from the file_location field of the dataframe.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"[SED]RR[0-9]+\")\n",
    "\n",
    "    file = df['file']\n",
    "\n",
    "    return re.search(pattern, file).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['acc'] = df.apply(get_srr_accession, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = df['count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spot_count(df, email, max_errors):\n",
    "    \"\"\"\n",
    "    Use the Entrez API to get the spot (read) count for that SRR number.\n",
    "    \"\"\"\n",
    "\n",
    "    srr_acc = df['acc']\n",
    "    \n",
    "    print (srr_acc)\n",
    "\n",
    "    # get SRR id\n",
    "    Entrez.email = email\n",
    "\n",
    "    error_count =0\n",
    "\n",
    "    while error_count < max_errors:\n",
    "\n",
    "        try:\n",
    "\n",
    "            handle = Entrez.esearch(db=\"sra\",term=srr_acc)\n",
    "\n",
    "            record = Entrez.read(handle)\n",
    "\n",
    "            handle.close()\n",
    "\n",
    "            srr_id = record[\"IdList\"][0]\n",
    "\n",
    "            break\n",
    "\n",
    "        except:\n",
    "\n",
    "            print ('error occured collecting ID ', srr_acc, error_count)\n",
    "\n",
    "            time.sleep(10)\n",
    "\n",
    "            error_count = error_count +1\n",
    "\n",
    "\n",
    "    # get SRR summary\n",
    "\n",
    "    error_count =0\n",
    "\n",
    "    while error_count < max_errors:\n",
    "\n",
    "        try:\n",
    "\n",
    "            handle = Entrez.esummary(db='sra', id=srr_id)\n",
    "\n",
    "            record = Entrez.read(handle)\n",
    "\n",
    "            handle.close()\n",
    "\n",
    "            my_xml = record[0]['Runs']\n",
    "\n",
    "            # Parse XML\n",
    "            xml_object = ET.fromstringlist([\"<root>\", my_xml, \"</root>\"])\n",
    "\n",
    "            # Get total_spots (reads)\n",
    "            for child in xml_object:\n",
    "\n",
    "                if child.attrib['acc'] == srr_acc:\n",
    "\n",
    "                    print (srr_acc, child.attrib['total_spots'])\n",
    "\n",
    "                    return int(child.attrib['total_spots'])\n",
    "\n",
    "        except:\n",
    "\n",
    "            print ('error occured collecting spot count', srr_acc, error_count)\n",
    "\n",
    "            time.sleep(10)\n",
    "\n",
    "            error_count = error_count +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = my_list = list(df['acc'].unique())\n",
    "\n",
    "spot_df = pd.DataFrame(data2, columns=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_df['spot_count'] = spot_df.apply(get_spot_count, axis=1, args=['laitanawe@gmail.com', 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_df.to_csv('spot_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_count_dict ={}\n",
    "\n",
    "for row in spot_df.iterrows():\n",
    "    read_count_dict[(row[1]['acc'])] = row[1]['spot_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(df):\n",
    "    \n",
    "    srr = df['acc']\n",
    "    \n",
    "    read_count = read_count_dict[srr]\n",
    "    \n",
    "    return read_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['read_count'] = df.apply(normalise, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_values(df):\n",
    "    \n",
    "    return (df['count'] / df['read_count']) * 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalised_count'] = df.apply(normalise_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('typhi.ptyphi.comparison.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='type', y='normalised_count', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['type', 'seq']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped['type2'] = grouped.index.levels[0][ grouped.index.labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = grouped.pivot_table(index='seq', values='normalised_count', columns='type2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_diff(df):\n",
    "    \n",
    "    value1 = df['ptyphi']\n",
    "    value2 = df['typhi']\n",
    "    \n",
    "    pctdiff = abs(value1-value2)/((value1+value2)/2)*100\n",
    "    \n",
    "    return pctdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted['pct_diff'] = pivoted.apply(percent_diff,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = pivoted.sort_values('pct_diff')\n",
    "\n",
    "\n",
    "pivoted[['pct_diff']].plot(kind='bar', figsize =(75,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_change(df):\n",
    "    \n",
    "    value1 = df['ptyphi']\n",
    "    value2 = df['typhi']\n",
    "    \n",
    "    \n",
    "    return ((value2-value1) / value1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivoted['pct_change'] = pivoted.apply(pct_change, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = pivoted.sort_values('pct_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted['pct_change'].plot(kind='bar', figsize =(200,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Convert SAM files to BAM and bedGraph to calculate the coverage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "with open('analysis/sam2bam2bed.txt') as f:\n",
    "    command = \" \".join(line.rstrip(\"\\n\") for line in f)\n",
    "print (command)\n",
    "subprocess.check_call(command.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "with open('analysis/coverage.txt') as f:\n",
    "    command = \" \".join(line.rstrip(\"\\n\") for line in f)\n",
    "print (command)\n",
    "subprocess.check_call(command.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
